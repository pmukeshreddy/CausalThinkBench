{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Cell 1: Environment Setup\n\nprint(\"Uninstalling potentially conflicting libraries...\")\n!pip uninstall -y transformers accelerate peft torch optimum auto-gptq datasets evaluate\n\nprint(\"\\nInstalling a stable, compatible set of required libraries...\")\n# Install specific versions known to be compatible.\n!pip install -q \"transformers==4.40.2\"\n!pip install -q \"accelerate==0.29.3\"\n!pip install -q \"peft==0.10.0\"\n!pip install -q \"torch==2.3.0\"\n!pip install -q \"datasets==2.19.0\" \"evaluate==0.4.2\" \"pandas\"\n!pip install -q \"bert_score\" \"sentencepiece\" \"rouge_score\"\n# Install the AutoGPTQ library and its dependency, optimum.\n!pip install -q \"optimum==1.19.1\" \"auto-gptq==0.7.1\" --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu121/\n\nprint(\"\\nInstallations complete.\")\nprint(\"Important: Restart the session from the 'Run' menu before proceeding.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-20T20:07:30.625519Z","iopub.execute_input":"2025-07-20T20:07:30.625840Z","iopub.status.idle":"2025-07-20T20:12:55.258443Z","shell.execute_reply.started":"2025-07-20T20:07:30.625815Z","shell.execute_reply":"2025-07-20T20:12:55.257552Z"}},"outputs":[{"name":"stdout","text":"Uninstalling potentially conflicting libraries...\nFound existing installation: transformers 4.52.4\nUninstalling transformers-4.52.4:\n  Successfully uninstalled transformers-4.52.4\nFound existing installation: accelerate 1.8.1\nUninstalling accelerate-1.8.1:\n  Successfully uninstalled accelerate-1.8.1\nFound existing installation: peft 0.15.2\nUninstalling peft-0.15.2:\n  Successfully uninstalled peft-0.15.2\nFound existing installation: torch 2.6.0+cu124\nUninstalling torch-2.6.0+cu124:\n  Successfully uninstalled torch-2.6.0+cu124\n\u001b[33mWARNING: Skipping optimum as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping auto-gptq as it is not installed.\u001b[0m\u001b[33m\n\u001b[0mFound existing installation: datasets 3.6.0\nUninstalling datasets-3.6.0:\n  Successfully uninstalled datasets-3.6.0\n\u001b[33mWARNING: Skipping evaluate as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\nInstalling a stable, compatible set of required libraries...\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntorchtune 0.6.1 requires datasets, which is not installed.\nsentence-transformers 4.1.0 requires torch>=1.11.0, which is not installed.\nsentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.40.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.2/821.2 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nsentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.40.2 which is incompatible.\ntorchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.1 which is incompatible.\ntorchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.7.1 which is incompatible.\nfastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.2/779.2 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nsentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.40.2 which is incompatible.\ntorchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.3.0 which is incompatible.\ntorchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nsentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.40.2 which is incompatible.\ntorchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.3.0 which is incompatible.\ntorchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.3.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.3.1 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.0/417.0 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.5/23.5 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\nInstallations complete.\nImportant: Restart the session from the 'Run' menu before proceeding.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Cell 2: Load Model and Dataset\n\nimport torch\nimport pandas as pd\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom huggingface_hub import login\n\n# Configuration\nMODEL_NAME = \"TheBloke/Mistral-7B-Instruct-v0.2-GPTQ\"\nBENCHMARK_NAME = \"snli\"\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nprint(f\"Using device: {device}\")\n\n# Authentication\n# Your token is hard-coded. This is a security risk.\n# Delete this token from your Hugging Face account after use.\nHF_TOKEN_DIRECT = \"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\"\nlogin(token=HF_TOKEN_DIRECT)\nprint(\"Login to Hugging Face successful.\")\n\n\n# Load Model and Tokenizer\nprint(f\"Loading baseline model: {MODEL_NAME}...\")\nmodel = AutoModelForCausalLM.from_pretrained(\n    MODEL_NAME,\n    device_map=\"auto\",\n    trust_remote_code=True,\n)\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\nprint(\"Baseline model and tokenizer loaded.\")\n\n\n# Prepare Benchmark Dataset\nprint(f\"Loading benchmark dataset: {BENCHMARK_NAME}...\")\ndataset = load_dataset(BENCHMARK_NAME, split=\"test\")\n\n# Filter out examples where annotators did not agree (label == -1).\ndataset_filtered = dataset.filter(lambda example: example['label'] != -1)\nprint(f\"Original size of SNLI test set: {len(dataset)}\")\nprint(f\"Size after filtering ambiguous examples: {len(dataset_filtered)}\")\n\n# Use a smaller subset for the evaluation.\neval_subset = dataset_filtered.shuffle(seed=42).select(range(100))\nprint(f\"Using a subset of {len(eval_subset)} examples for this run.\")\nprint(\"Dataset prepared.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T20:12:55.260407Z","iopub.execute_input":"2025-07-20T20:12:55.260649Z","iopub.status.idle":"2025-07-20T20:13:55.187954Z","shell.execute_reply.started":"2025-07-20T20:12:55.260622Z","shell.execute_reply":"2025-07-20T20:13:55.187366Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nLogin to Hugging Face successful.\nLoading baseline model: TheBloke/Mistral-7B-Instruct-v0.2-GPTQ...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2d69433cbd54b09bd3b6a8bce16f9c7"}},"metadata":{}},{"name":"stderr","text":"2025-07-20 20:13:05.859100: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753042386.074778      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753042386.135364      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/4.16G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4b57e7cf8094543bbda1a73874677cf"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:4371: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb43d0751da14b56946330b9a3db3532"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0ab926986584d01b41736dd17465600"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15bd3379011c4a68bff419264179ee44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e8c3abfc07b48f39f79394641774406"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c9aace4601f49c5900f04d5561d70ee"}},"metadata":{}},{"name":"stdout","text":"Baseline model and tokenizer loaded.\nLoading benchmark dataset: snli...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading readme: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b139db509c7e43bab728d539aff88bad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/412k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"881cd995a85340c189377078d29b657a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/413k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad9933f3e68f4d9782267e230605eda0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/19.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff92636d89f249c2961ba501ad778805"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b3c521a9bea4f13afc1431646ab669e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aff8656f347c4d8a9a5967e862f89dbc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/550152 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ae5c965f4c94150bc4c2c1b7ac406ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b82953947e1840eb97328d6a8243fa20"}},"metadata":{}},{"name":"stdout","text":"Original size of SNLI test set: 10000\nSize after filtering ambiguous examples: 9824\nUsing a subset of 100 examples for this run.\nDataset prepared.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Cell 3: Run Evaluation Loop\n\nfrom tqdm import tqdm\n\n# Define the prompt template for the model.\nprompt_template = \"\"\"### INSTRUCTION:\nExplain the step-by-step reasoning that connects the following premise to the hypothesis.\n\n### PREMISE:\n{premise}\n\n### CONCLUSION:\n{hypothesis}\n\n### RESPONSE:\n\"\"\"\n\nprint(f\"Running evaluation loop on {len(eval_subset)} examples...\")\nresults_list = []\n\nmodel.eval()\nwith torch.no_grad():\n    for example in tqdm(eval_subset):\n        prompt = prompt_template.format(premise=example['premise'], hypothesis=example['hypothesis'])\n        \n        # Tokenize the input prompt.\n        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True)\n        \n        # Generate a response from the model.\n        # Explicitly move input tensors to the primary GPU.\n        outputs = model.generate(input_ids=inputs[\"input_ids\"].to(device), max_new_tokens=128, do_sample=False)\n        \n        # Decode the generated tokens into text.\n        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n        \n        # Clean the output to isolate the response.\n        try:\n            explanation = generated_text.split(\"### RESPONSE:\")[1].strip()\n        except IndexError:\n            explanation = \"Model did not generate a valid response.\"\n\n        results_list.append({\n            \"premise\": example['premise'],\n            \"hypothesis\": example['hypothesis'],\n            \"true_label_id\": example['label'],\n            \"generated_explanation\": explanation\n        })\n\n# Store results in a pandas DataFrame.\nresults_df = pd.DataFrame(results_list)\nprint(\"Evaluation complete. Results collected.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T20:13:55.188659Z","iopub.execute_input":"2025-07-20T20:13:55.189111Z","iopub.status.idle":"2025-07-20T23:28:43.708502Z","shell.execute_reply.started":"2025-07-20T20:13:55.189092Z","shell.execute_reply":"2025-07-20T23:28:43.707699Z"}},"outputs":[{"name":"stdout","text":"Running evaluation loop on 100 examples...\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n  1%|          | 1/100 [00:51<1:25:32, 51.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n  2%|▏         | 2/100 [02:00<1:40:38, 61.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n  3%|▎         | 3/100 [04:24<2:40:31, 99.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n  4%|▍         | 4/100 [06:50<3:08:20, 117.71s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n  5%|▌         | 5/100 [09:16<3:22:27, 127.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n  6%|▌         | 6/100 [11:42<3:29:55, 134.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n  7%|▋         | 7/100 [13:14<3:06:33, 120.36s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n  8%|▊         | 8/100 [15:40<3:17:01, 128.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n  9%|▉         | 9/100 [16:39<2:42:03, 106.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 10%|█         | 10/100 [18:47<2:49:55, 113.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 11%|█         | 11/100 [20:21<2:39:32, 107.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 12%|█▏        | 12/100 [22:47<2:54:50, 119.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 13%|█▎        | 13/100 [24:38<2:49:02, 116.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 14%|█▍        | 14/100 [27:04<2:59:45, 125.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 15%|█▌        | 15/100 [29:28<3:05:54, 131.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 16%|█▌        | 16/100 [30:40<2:38:42, 113.36s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 17%|█▋        | 17/100 [33:06<2:50:19, 123.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 18%|█▊        | 18/100 [34:04<2:21:34, 103.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 19%|█▉        | 19/100 [36:30<2:36:58, 116.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 20%|██        | 20/100 [38:56<2:46:53, 125.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 21%|██        | 21/100 [41:22<2:52:59, 131.38s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 22%|██▏       | 22/100 [42:36<2:28:25, 114.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 23%|██▎       | 23/100 [43:37<2:06:15, 98.38s/it] The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 24%|██▍       | 24/100 [45:14<2:04:01, 97.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 25%|██▌       | 25/100 [47:40<2:20:22, 112.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 26%|██▌       | 26/100 [50:00<2:28:49, 120.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 27%|██▋       | 27/100 [52:26<2:36:01, 128.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 28%|██▊       | 28/100 [54:11<2:25:27, 121.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 29%|██▉       | 29/100 [55:14<2:02:40, 103.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 30%|███       | 30/100 [57:28<2:11:43, 112.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 31%|███       | 31/100 [59:54<2:21:13, 122.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 32%|███▏      | 32/100 [1:02:20<2:27:01, 129.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 33%|███▎      | 33/100 [1:03:47<2:10:25, 116.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 34%|███▍      | 34/100 [1:06:12<2:18:05, 125.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 35%|███▌      | 35/100 [1:08:38<2:22:35, 131.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 36%|███▌      | 36/100 [1:11:04<2:24:57, 135.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 37%|███▋      | 37/100 [1:12:19<2:03:34, 117.70s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 38%|███▊      | 38/100 [1:14:45<2:10:21, 126.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 39%|███▉      | 39/100 [1:16:35<2:03:08, 121.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 40%|████      | 40/100 [1:19:00<2:08:32, 128.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 41%|████      | 41/100 [1:19:44<1:41:15, 102.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 42%|████▏     | 42/100 [1:22:10<1:51:58, 115.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 43%|████▎     | 43/100 [1:24:36<1:58:36, 124.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 44%|████▍     | 44/100 [1:26:17<1:49:57, 117.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 45%|████▌     | 45/100 [1:28:43<1:55:42, 126.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 46%|████▌     | 46/100 [1:31:09<1:58:55, 132.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 47%|████▋     | 47/100 [1:33:20<1:56:26, 131.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 48%|████▊     | 48/100 [1:35:06<1:47:32, 124.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 49%|████▉     | 49/100 [1:37:32<1:51:01, 130.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 50%|█████     | 50/100 [1:39:58<1:52:39, 135.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 51%|█████     | 51/100 [1:41:51<1:45:12, 128.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 52%|█████▏    | 52/100 [1:43:16<1:32:22, 115.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 53%|█████▎    | 53/100 [1:44:28<1:20:10, 102.36s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 54%|█████▍    | 54/100 [1:46:35<1:24:17, 109.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 55%|█████▌    | 55/100 [1:47:53<1:15:09, 100.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 56%|█████▌    | 56/100 [1:50:19<1:23:31, 113.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 57%|█████▋    | 57/100 [1:51:34<1:13:19, 102.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 58%|█████▊    | 58/100 [1:52:16<58:59, 84.27s/it]   The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 59%|█████▉    | 59/100 [1:53:27<54:47, 80.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 60%|██████    | 60/100 [1:55:21<1:00:12, 90.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 61%|██████    | 61/100 [1:56:20<52:38, 80.99s/it]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 62%|██████▏   | 62/100 [1:58:42<1:02:58, 99.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 63%|██████▎   | 63/100 [2:01:08<1:09:54, 113.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 64%|██████▍   | 64/100 [2:02:17<59:55, 99.87s/it]   The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 65%|██████▌   | 65/100 [2:04:42<1:06:18, 113.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 66%|██████▌   | 66/100 [2:07:08<1:09:54, 123.36s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 67%|██████▋   | 67/100 [2:09:34<1:11:33, 130.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 68%|██████▊   | 68/100 [2:12:00<1:11:54, 134.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 69%|██████▉   | 69/100 [2:12:59<57:57, 112.16s/it]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 70%|███████   | 70/100 [2:15:25<1:01:08, 122.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 71%|███████   | 71/100 [2:17:07<56:04, 116.02s/it]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 72%|███████▏  | 72/100 [2:18:33<50:01, 107.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 73%|███████▎  | 73/100 [2:20:59<53:27, 118.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 74%|███████▍  | 74/100 [2:22:44<49:39, 114.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 75%|███████▌  | 75/100 [2:25:10<51:39, 124.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 76%|███████▌  | 76/100 [2:27:36<52:13, 130.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 77%|███████▋  | 77/100 [2:30:02<51:48, 135.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 78%|███████▊  | 78/100 [2:31:42<45:43, 124.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 79%|███████▉  | 79/100 [2:34:08<45:52, 131.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 80%|████████  | 80/100 [2:36:34<45:10, 135.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 81%|████████  | 81/100 [2:37:48<37:04, 117.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 82%|████████▏ | 82/100 [2:39:12<32:10, 107.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 83%|████████▎ | 83/100 [2:41:38<33:39, 118.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 84%|████████▍ | 84/100 [2:44:04<33:50, 126.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 85%|████████▌ | 85/100 [2:46:30<33:09, 132.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 86%|████████▌ | 86/100 [2:47:54<27:33, 118.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 87%|████████▋ | 87/100 [2:50:20<27:23, 126.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 88%|████████▊ | 88/100 [2:51:36<22:17, 111.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 89%|████████▉ | 89/100 [2:53:05<19:11, 104.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 90%|█████████ | 90/100 [2:55:31<19:30, 117.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 91%|█████████ | 91/100 [2:57:07<16:35, 110.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 92%|█████████▏| 92/100 [2:59:33<16:09, 121.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 93%|█████████▎| 93/100 [3:00:48<12:31, 107.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 94%|█████████▍| 94/100 [3:03:14<11:53, 118.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 95%|█████████▌| 95/100 [3:04:55<09:28, 113.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 96%|█████████▌| 96/100 [3:05:49<06:22, 95.67s/it] The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 97%|█████████▋| 97/100 [3:08:15<05:32, 110.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 98%|█████████▊| 98/100 [3:10:00<03:37, 108.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 99%|█████████▉| 99/100 [3:12:26<02:00, 120.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n100%|██████████| 100/100 [3:14:48<00:00, 116.88s/it]","output_type":"stream"},{"name":"stdout","text":"Evaluation complete. Results collected.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Cell 4: Analyze Results (Corrected with Manual Metric Calculation)\n\n# Import the metric libraries directly, bypassing the broken evaluate.load()\nfrom rouge_score import rouge_scorer\nfrom bert_score import score as bert_score_calc\nimport numpy as np\nimport pandas as pd\nimport torch\n\nprint(\"Analyzing results...\")\n\n# --- Qualitative Review ---\nprint(\"\\nQualitative Review of Baseline Model's Reasoning (Top 10 Results):\")\n\n# Define human-readable labels.\nlabels_map = {0: \"Entailment\", 1: \"Neutral\", 2: \"Contradiction\"}\nresults_df['true_label'] = results_df['true_label_id'].map(labels_map)\n\n# Configure pandas for better display.\npd.set_option('display.max_colwidth', 400)\ndisplay(results_df.head(10)[['premise', 'hypothesis', 'true_label', 'generated_explanation']])\n\n\n# --- Automated Metrics (Manual Calculation) ---\nprint(\"\\nAutomated Metrics on 'Entailment' Examples:\")\n\n# Filter for examples that are true entailments.\nentailment_df = results_df[results_df['true_label'] == 'Entailment']\n\nif not entailment_df.empty:\n    predictions = entailment_df['generated_explanation'].tolist()\n    references = entailment_df['hypothesis'].tolist()\n\n    # 1. Manual ROUGE-2 Calculation\n    print(\"Calculating ROUGE scores...\")\n    scorer = rouge_scorer.RougeScorer(['rouge2'], use_stemmer=True)\n    rouge2_scores = [scorer.score(ref, pred)['rouge2'].fmeasure for ref, pred in zip(references, predictions)]\n    avg_rouge2 = np.mean(rouge2_scores)\n    \n    # 2. Manual BERTScore Calculation\n    print(\"Calculating BERTScore... (This may take a moment)\")\n    # BERTScore needs to know the GPU device if available\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    # The score function returns Precision, Recall, and F1 tensors. We want the F1.\n    P, R, F1 = bert_score_calc(predictions, references, lang=\"en\", device=device, verbose=False)\n    # Calculate the average of the F1 scores.\n    avg_bert_f1 = F1.mean().item()\n\n    print(f\"BERTScore F1 (Semantic Similarity): {avg_bert_f1:.4f}\")\n    print(f\"ROUGE-2 Score (Lexical Overlap):   {avg_rouge2:.4f}\")\n\nelse:\n    print(\"No 'Entailment' examples were present in the random subset to calculate scores.\")\n\nprint(\"\\nPipeline execution finished.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T23:33:38.563405Z","iopub.execute_input":"2025-07-20T23:33:38.563692Z","iopub.status.idle":"2025-07-20T23:33:49.410907Z","shell.execute_reply.started":"2025-07-20T23:33:38.563671Z","shell.execute_reply":"2025-07-20T23:33:49.410213Z"}},"outputs":[{"name":"stdout","text":"Analyzing results...\n\nQualitative Review of Baseline Model's Reasoning (Top 10 Results):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                                                                                                          premise  \\\n0                                                                                  A man is using what looks to be a fax machine.   \n1                                                         A man in a grassy field throws a stick for a group of three brown dogs.   \n2                                                                      Two people bicycle on a path separated by small mountains.   \n3                                                                            Workers wearing orange vests stand near rail tracks.   \n4  Three men in hats and a woman in a red shirt examine the produce presented to them by the man in the blue shirt and white hat.   \n5                                                                 A man is talking on a cellphone while filling his car with gas.   \n6                                                             An older gentleman looks at the camera while he is building a deck.   \n7                                                                            A woman is leaning against a wall with her shoe off.   \n8                                                                       A small quaint town all lit up during the holiday season.   \n9            A young woman cooks a meal in a wok while conversing with another woman, as an illuminated shrine to Mr. T looks on.   \n\n                                                                        hypothesis  \\\n0                                A person is using what looks to be a fax machine.   \n1                                                      A man is playing with dogs.   \n2                                             Two people are hiking up a mountain.   \n3                          Workers wearing orange are about to repair rail tracks.   \n4                                              The group is going to buy something   \n5                           A man talks to his boss while getting gas for his car.   \n6  An older gentleman looks away from the camera while he is building a birdhouse.   \n7                       A woman is standing in high heels, leaning against a wall.   \n8                                                        The town is totally dark.   \n9                                         Both of these women are clinically mute.   \n\n      true_label  \\\n0     Entailment   \n1     Entailment   \n2  Contradiction   \n3        Neutral   \n4        Neutral   \n5        Neutral   \n6  Contradiction   \n7  Contradiction   \n8  Contradiction   \n9  Contradiction   \n\n                                                                                                                                                                                                                                                                                                                                                                                             generated_explanation  \n0                                                                                                                                                                                 The conclusion follows directly from the premise. The man's use of the fax machine is what is being described in the premise, and the conclusion simply restates that a person is using a fax machine based on that observation.  \n1                                                                                                          The man in the premise is engaging in an activity with the dogs. He is throwing a stick for them to retrieve and play with. This is a common behavior associated with playing with dogs. Therefore, based on the information given in the premise, it can be concluded that a man is playing with dogs.  \n2  The premise describes two people bicycling on a path, but the conclusion states that they are hiking up a mountain. This is a significant difference, as bicycling and hiking are two distinct activities.\\n\\nTo understand how the premise could lead to the conclusion, we need to consider some possible connections. However, without more information, it's difficult to make a definitive conclusion. ...  \n3  The premise states that workers are wearing orange vests and they are standing near rail tracks. This observation alone does not definitively prove that the workers are about to repair the rail tracks. However, it is a common practice for workers to wear orange vests when they are working on or near rail tracks for safety reasons. Additionally, repairing rail tracks is a common activity that r...  \n4  The premise describes a scene where three men and a woman are examining the produce presented to them by one of the men. While the premise does not explicitly state that the group intends to buy the produce, it is a common behavior for people to examine items before making a purchase. Therefore, based on this assumption, it can be inferred that the group is likely to buy something.\\n\\nHere's a...  \n5  The premise states that a man is talking on a cellphone while filling his car with gas. This means that the man is engaged in a conversation while performing another task, which is getting gas for his car. The hypothesis suggests that the man is talking to his boss. While we don't have any direct evidence from the premise that the man is talking to his boss, we can't rule it out either. There'...  \n6  The premise and the conclusion are not directly related. The premise only describes an action (building a deck) and the appearance (older gentleman looking at the camera) of the person performing the action. The conclusion, on the other hand, describes a different action (building a birdhouse) and a different behavior (looking away from the camera). There is no logical connection between the t...  \n7  The hypothesis goes beyond the information given in the premise. However, based on the given premise alone, it's impossible to rule out the hypothesis. Here's the reasoning:\\n\\n1. The premise states that a woman is leaning against a wall with one shoe off.\\n2. The hypothesis states that a woman is standing in high heels, leaning against a wall.\\n3. The premise does not provide any information ...  \n8                                                                                                                                                 The premise and the conclusion are contradictory to each other. The premise describes a town that is all lit up during the holiday season, while the conclusion states that the town is totally dark. There is no logical connection between the two statements.  \n9  The premise and the conclusion are not logically connected. The premise describes an action (cooking in a wok while conversing) and the presence of an object (an illuminated shrine to Mr. T), but it does not provide any information about the women's abilities to speak or communicate in any way. The conclusion, on the other hand, asserts that both women are clinically mute, which is not support...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>premise</th>\n      <th>hypothesis</th>\n      <th>true_label</th>\n      <th>generated_explanation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A man is using what looks to be a fax machine.</td>\n      <td>A person is using what looks to be a fax machine.</td>\n      <td>Entailment</td>\n      <td>The conclusion follows directly from the premise. The man's use of the fax machine is what is being described in the premise, and the conclusion simply restates that a person is using a fax machine based on that observation.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A man in a grassy field throws a stick for a group of three brown dogs.</td>\n      <td>A man is playing with dogs.</td>\n      <td>Entailment</td>\n      <td>The man in the premise is engaging in an activity with the dogs. He is throwing a stick for them to retrieve and play with. This is a common behavior associated with playing with dogs. Therefore, based on the information given in the premise, it can be concluded that a man is playing with dogs.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Two people bicycle on a path separated by small mountains.</td>\n      <td>Two people are hiking up a mountain.</td>\n      <td>Contradiction</td>\n      <td>The premise describes two people bicycling on a path, but the conclusion states that they are hiking up a mountain. This is a significant difference, as bicycling and hiking are two distinct activities.\\n\\nTo understand how the premise could lead to the conclusion, we need to consider some possible connections. However, without more information, it's difficult to make a definitive conclusion. ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Workers wearing orange vests stand near rail tracks.</td>\n      <td>Workers wearing orange are about to repair rail tracks.</td>\n      <td>Neutral</td>\n      <td>The premise states that workers are wearing orange vests and they are standing near rail tracks. This observation alone does not definitively prove that the workers are about to repair the rail tracks. However, it is a common practice for workers to wear orange vests when they are working on or near rail tracks for safety reasons. Additionally, repairing rail tracks is a common activity that r...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Three men in hats and a woman in a red shirt examine the produce presented to them by the man in the blue shirt and white hat.</td>\n      <td>The group is going to buy something</td>\n      <td>Neutral</td>\n      <td>The premise describes a scene where three men and a woman are examining the produce presented to them by one of the men. While the premise does not explicitly state that the group intends to buy the produce, it is a common behavior for people to examine items before making a purchase. Therefore, based on this assumption, it can be inferred that the group is likely to buy something.\\n\\nHere's a...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>A man is talking on a cellphone while filling his car with gas.</td>\n      <td>A man talks to his boss while getting gas for his car.</td>\n      <td>Neutral</td>\n      <td>The premise states that a man is talking on a cellphone while filling his car with gas. This means that the man is engaged in a conversation while performing another task, which is getting gas for his car. The hypothesis suggests that the man is talking to his boss. While we don't have any direct evidence from the premise that the man is talking to his boss, we can't rule it out either. There'...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>An older gentleman looks at the camera while he is building a deck.</td>\n      <td>An older gentleman looks away from the camera while he is building a birdhouse.</td>\n      <td>Contradiction</td>\n      <td>The premise and the conclusion are not directly related. The premise only describes an action (building a deck) and the appearance (older gentleman looking at the camera) of the person performing the action. The conclusion, on the other hand, describes a different action (building a birdhouse) and a different behavior (looking away from the camera). There is no logical connection between the t...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>A woman is leaning against a wall with her shoe off.</td>\n      <td>A woman is standing in high heels, leaning against a wall.</td>\n      <td>Contradiction</td>\n      <td>The hypothesis goes beyond the information given in the premise. However, based on the given premise alone, it's impossible to rule out the hypothesis. Here's the reasoning:\\n\\n1. The premise states that a woman is leaning against a wall with one shoe off.\\n2. The hypothesis states that a woman is standing in high heels, leaning against a wall.\\n3. The premise does not provide any information ...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>A small quaint town all lit up during the holiday season.</td>\n      <td>The town is totally dark.</td>\n      <td>Contradiction</td>\n      <td>The premise and the conclusion are contradictory to each other. The premise describes a town that is all lit up during the holiday season, while the conclusion states that the town is totally dark. There is no logical connection between the two statements.</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>A young woman cooks a meal in a wok while conversing with another woman, as an illuminated shrine to Mr. T looks on.</td>\n      <td>Both of these women are clinically mute.</td>\n      <td>Contradiction</td>\n      <td>The premise and the conclusion are not logically connected. The premise describes an action (cooking in a wok while conversing) and the presence of an object (an illuminated shrine to Mr. T), but it does not provide any information about the women's abilities to speak or communicate in any way. The conclusion, on the other hand, asserts that both women are clinically mute, which is not support...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nAutomated Metrics on 'Entailment' Examples:\nCalculating ROUGE scores...\nCalculating BERTScore... (This may take a moment)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3feaaa2ebb0469082907291557f14a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d43e44e6028a45bd8f2743916d345d68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a212d5a4ba194d18b0a7032a0edac10f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"171c26ee552641bfa210affd72d968da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dcbecb332154bd689ded8f452a502f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d223ebf13f6c458ab154d23f08e72db9"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"BERTScore F1 (Semantic Similarity): 0.8667\nROUGE-2 Score (Lexical Overlap):   0.1183\n\nPipeline execution finished.\n","output_type":"stream"}],"execution_count":7}]}